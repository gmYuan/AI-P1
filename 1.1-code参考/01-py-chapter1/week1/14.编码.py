# æµ‹è¯•æ•°æ®ï¼šç”¨äºå­—ç¬¦ç¼–ç åˆ†æçš„å­—ç¬¦ä¸²åˆ—è¡¨
test_texts = ["Hello World", "Hello ä¸–ç•Œ ğŸŒ", "Pythonç¼–ç¨‹ğŸ˜ŠğŸ‰"]


def analyze_text_encoding(text0):
    if not isinstance(text, str):  # p instanceof Person
        raise TypeError("è¾“å…¥çš„å¿…é¡»æ˜¯å­—ç¬¦ä¸²")
    # å­—ç¬¦æ€»æ•°
    total_chars = len(text)
    ascii_chars = 0
    unicode_chars = 0
    character_details = []
    for char in text:
        # è·å–å­—ç¬¦å¯¹åº”çš„unicodeç ç‚¹ å°±æ˜¯æ­¤å­—ç¬¦åœ¨unicodeä¸­çš„ç¼–å·
        char_unicode = ord(char)
        char_utf8_bytes = char.encode("utf-8")
        # è·å–æ­¤å­—ç¬¦å¯¹åº”çš„å­—èŠ‚æ•°
        char_utf8_bytes_len = len(char_utf8_bytes)
        # åˆ¤æ–­æ­¤å­—ç¬¦çš„ç ç‚¹æ˜¯å¦å°äº128
        if char_unicode < 128:
            ascii_chars += 1
        else:
            unicode_chars += 1
        character_details.append(
            {
                "char": char,
                "unicode": f"U+{char_unicode:04X}",
                "char_utf8_bytes": char_utf8_bytes_len,
                "is_ascii": char_unicode < 128,
            }
        )
    utf8_bytes = len(text.encode("utf-8"))
    # è¿”å›åˆ†æç»“æœå­—å…¸
    return {
        "total_chars": total_chars,
        "ascii_chars": ascii_chars,
        "unicode_chars": unicode_chars,
        "utf8_bytes": utf8_bytes,
        "character_details": character_details,
    }


"""
# éå†æµ‹è¯•æ–‡æœ¬å¹¶å±•ç¤ºåˆ†æç»“æœ
for text in test_texts:
    # åˆ†æå½“å‰æ–‡æœ¬
    result = analyze_text_encoding(text)
    # æ‰“å°å½“å‰æ–‡æœ¬å†…å®¹
    print(f'\næ–‡æœ¬: "{text}"')
    # æ‰“å°æ–‡æœ¬æ€»å­—ç¬¦æ•°
    print(f"æ€»å­—ç¬¦æ•°: {result['total_chars']}")
    # æ‰“å°ASCIIå­—ç¬¦æ•°ç›®
    print(f"ASCIIå­—ç¬¦æ•°: {result['ascii_chars']}")
    # æ‰“å°éASCIIçš„Unicodeå­—ç¬¦æ•°ç›®
    print(f"Unicodeå­—ç¬¦æ•°: {result['unicode_chars']}")
    # æ‰“å°UTF-8ç¼–ç å­—èŠ‚æ•°
    print(f"UTF-8å­—èŠ‚æ•°: {result['utf8_bytes']}")

    # æ˜¾ç¤ºå‰3ä¸ªå­—ç¬¦çš„è¯¦ç»†ç¼–ç ä¿¡æ¯
    print("å­—ç¬¦è¯¦æƒ… (å‰3ä¸ª):")
    for detail in result["character_details"][:3]:
        # æ‰“å°æ¯ä¸ªå­—ç¬¦çš„è¯¦ç»†ç¼–ç ä¿¡æ¯
        print(f"  {detail}")



def convert_encoding(text, target_encoding="utf-8"):
    if not isinstance(text, str):  # p instanceof Person
        raise TypeError("è¾“å…¥çš„å¿…é¡»æ˜¯å­—ç¬¦ä¸²")
    try:
        return text.encode(target_encoding)
    except UnicodeEncodeError:
        if target_encoding.lower() == "ascii":
            # ä½¿ç”¨errors="replace"è¡¨ç¤ºæŠŠä¸èƒ½è½¬æ¢çš„ç¼–ç çš„å­—ç¬¦æ›¿æ¢ä¸º?
            ascii_text = text.encode("ascii", errors="replace")
            return ascii_text
        else:
            try:
                return text.encode(target_encoding, errors="replace")
            except (LookupError, UnicodeEncodeError):
                utf8_bytes = text.encode("utf-8", errors="replace")
                return utf8_bytes
"""


def detect_and_fix_encoding(data_bytes, possible_encodings=["utf-8", "gbk", "ascii"]):
    if not isinstance(data_bytes, bytes):
        raise TypeError("è¾“å…¥å¿…é¡»æ˜¯å­—èŠ‚ç±»å‹")
    best_result = {
        "detected_encoding": None,
        "decoded_text": "",
        "success": False,
        "error_info": "",
    }
    for encoding in possible_encodings:
        try:
            # ç”¨å½“å‰çš„ç¼–ç å°è¯•è§£ç 
            decoded_text = data_bytes.decode(encoding)
            error_chars = decoded_text.count("?")
            error_ratio = error_chars / len(decoded_text) if decoded_text else 1
            # å¦‚æœé—®å·çš„å‡ºç°çš„æ¯”ç‡å°äº30%,è®¤ä¸ºè§£ç æˆåŠŸ
            if error_ratio < 0.3:
                best_result = {
                    "detected_encoding": encoding,
                    "decoded_text": decoded_text,
                    "success": True,
                    "error_info": "",
                }
                break

        except (UnicodeDecodeError, LookupError) as e:
            continue
    # å¦‚æœæ‰€æœ‰çš„æ­£å¸¸è§£ç éƒ½å¤±è´¥äº†ï¼Œåˆ™å°è¯•é‡‡ç”¨errors='replace'æ¥è¿›è¡Œæ›¿æ¢
    if not best_result["success"]:
        for encoding in possible_encodings:
            try:
                decoded_text = data_bytes.decode(encoding, errors="replace")
                best_result = {
                    "detected_encoding": encoding,
                    "decoded_text": decoded_text,
                    "success": False,
                    "error_info": f"ä½¿ç”¨{encoding}è§£ç ä»æ—©åˆ°æ™š åŒ…å«æ›¿æ¢å­—ç¬¦",
                }
                break
            except LookupError:
                continue
    return best_result


# å®šä¹‰ä¹±ç æ£€æµ‹æµ‹è¯•ç”¨ä¾‹åˆ—è¡¨ï¼ŒåŒ…å«è¦è½¬æ¢çš„æ–‡æœ¬å’Œé‡‡ç”¨çš„ç¼–ç 
test_cases = [("Hello ä¸–ç•Œ", "utf-8"), ("Pythonç¼–ç¨‹", "utf-8")]

# éå†æ¯ä¸ªæµ‹è¯•ç”¨ä¾‹è¿›è¡Œç¼–ç æ£€æµ‹å’Œä¿®å¤
for text, encoding in test_cases:
    # å°†æ–‡æœ¬ç”¨æŒ‡å®šç¼–ç è½¬ä¸ºå­—èŠ‚æ•°æ®
    encoded_bytes = text.encode(encoding)
    # è‡ªåŠ¨æ£€æµ‹å¹¶ä¿®å¤ç¼–ç 
    result = detect_and_fix_encoding(encoded_bytes)

    # æ‰“å°åŸå§‹æ–‡æœ¬åŠå…¶ç¼–ç ç±»å‹
    print(f'\nåŸå§‹æ–‡æœ¬: "{text}" (ä½¿ç”¨{encoding}ç¼–ç )')
    # æ‰“å°æ£€æµ‹åˆ°çš„ç¼–ç ç±»å‹
    print(f"æ£€æµ‹åˆ°ç¼–ç : {result['detected_encoding']}")
    # æ‰“å°æ˜¯å¦è§£ç æˆåŠŸ
    print(f"è§£ç æˆåŠŸ: {result['success']}")
    # æ‰“å°å®é™…è§£ç å¾—åˆ°çš„æ–‡æœ¬
    print(f"è§£ç ç»“æœ: {result['decoded_text']}")
    # å¦‚æœæœ‰é”™è¯¯ä¿¡æ¯åˆ™æ‰“å°
    if result["error_info"]:
        print(f"é”™è¯¯ä¿¡æ¯: {result['error_info']}")
